{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-14T17:22:18.534783900Z",
     "start_time": "2025-03-14T17:22:12.947153500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import h5py\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.transforms import v2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sys\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c3fa5c69dc9bda7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ellipsis, slice(None, None, None))\n"
     ]
    }
   ],
   "source": [
    "is_local = True # todo\n",
    "\n",
    "# Experiment\n",
    "seed = 1000 if is_local else int(sys.argv[-2])\n",
    "torch.manual_seed(seed)\n",
    "image_size = 256\n",
    "\n",
    "# Data: which wavenumbers are even allowed to be considered?\n",
    "wv_start = 0\n",
    "wv_end = 965\n",
    "\n",
    "# Data loading\n",
    "test_set_fraction = 0.2\n",
    "val_set_fraction = 0.2\n",
    "batch_size= 64\n",
    "patch_dim = 1\n",
    "use_augmentation = False\n",
    "samples_to_train = 1000 # todo 10000\n",
    "\n",
    "# dimensionality reduction parameters\n",
    "r_method = 'fixed' # 'fixed' or 'pca'\n",
    "reduce_dim = 4 if is_local else int(sys.argv[-1])\n",
    "channels_used = np.s_[...,:] # used only when r_method = 'fixed'\n",
    "print(channels_used)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T17:22:18.544831Z",
     "start_time": "2025-03-14T17:22:18.531693Z"
    }
   },
   "id": "222959fcfa561aff",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 228 cores\n",
      "Using 965/965 wavenumbers\n"
     ]
    }
   ],
   "source": [
    "def csf_fp(filepath):\n",
    "    return filepath.replace('D:/datasets','D:/datasets' if is_local else './')\n",
    "\n",
    "master = pd.read_excel(csf_fp(rf'D:/datasets/pcuk2023_ftir_whole_core/master_sheet.xlsx'))\n",
    "slide = master['slide'].to_numpy()\n",
    "patient_id = master['patient_id'].to_numpy()\n",
    "hdf5_filepaths = np.array([csf_fp(fp) for fp in master['hdf5_filepath']])\n",
    "annotation_filepaths = np.array([csf_fp(fp) for fp in master['annotation_filepath']])\n",
    "mask_filepaths = np.array([csf_fp(fp) for fp in master['mask_filepath']])\n",
    "wavenumbers = np.load(csf_fp(f'D:/datasets/pcuk2023_ftir_whole_core/wavenumbers.npy'))[wv_start:wv_end]\n",
    "wavenumbers_used = wavenumbers[channels_used]\n",
    "\n",
    "annotation_class_colors = np.array([[0,255,0],[128,0,128],[255,0,255],[0,0,255],[255,165,0],[255,0,0]])\n",
    "annotation_class_names = np.array(['epithelium_n','stroma_n','epithelium_c','stroma_c','corpora_amylacea','blood'])\n",
    "n_classes = len(annotation_class_names)\n",
    "print(f\"Loaded {len(slide)} cores\")\n",
    "print(f\"Using {len(wavenumbers_used)}/{len(wavenumbers)} wavenumbers\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T17:22:18.644518500Z",
     "start_time": "2025-03-14T17:22:18.542762800Z"
    }
   },
   "id": "a78af96389a4cd31",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Datasets, Dataloaders"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaba53c2e93ca461"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients per data split:\n",
      "\tTRAIN: 130\n",
      "\tVAL: 51\n",
      "\tTEST: 47\n"
     ]
    }
   ],
   "source": [
    "unique_pids = np.unique(patient_id)\n",
    "pids_trainval, pids_test, _, _ = train_test_split(\n",
    "    unique_pids, np.zeros_like(unique_pids), test_size=test_set_fraction, random_state=seed)\n",
    "pids_train, pids_val, _, _ = train_test_split(\n",
    "    pids_trainval, np.zeros_like(pids_trainval), test_size=(val_set_fraction/(1-test_set_fraction)), random_state=seed)\n",
    "where_train = np.where(np.isin(patient_id,pids_train))\n",
    "where_val = np.where(np.isin(patient_id,pids_val))\n",
    "where_test = np.where(np.isin(patient_id,pids_test))\n",
    "print(f\"Patients per data split:\\n\\tTRAIN: {len(where_train[0])}\\n\\tVAL: {len(where_val[0])}\\n\\tTEST: {len(where_test[0])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T17:22:18.650449300Z",
     "start_time": "2025-03-14T17:22:18.642457400Z"
    }
   },
   "id": "e4655cf38851b265",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ftir_patching_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,hdf5_filepaths, mask_filepaths, annotation_filepaths, channels_use,\n",
    "                 patch_dim=25, augment=True,):\n",
    "        \n",
    "        # Define data paths\n",
    "        self.hdf5_filepaths = hdf5_filepaths\n",
    "        self.mask_filepaths = mask_filepaths\n",
    "        self.annotation_filepaths = annotation_filepaths\n",
    "        self.augment = augment\n",
    "        \n",
    "        # patch dimensions\n",
    "        self.patch_dim = patch_dim\n",
    "        self.patch_minus = patch_dim //2; self.patch_plus = 1 + (patch_dim // 2)\n",
    "        self.channels = channels_use\n",
    "        \n",
    "        # class data\n",
    "        self.annotation_class_colors = annotation_class_colors\n",
    "        self.annotation_class_names = annotation_class_names\n",
    "        self.total_sampled = torch.zeros(len(self.annotation_class_colors))\n",
    "        \n",
    "        # define data augmentation pipeline\n",
    "        self.transforms = v2.Compose([\n",
    "            v2.RandomHorizontalFlip(p=0.5),\n",
    "            v2.RandomVerticalFlip(p=0.5),\n",
    "        ])\n",
    "        \n",
    "        # Open every core hdf5 file\n",
    "        self.open()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.total_pixels\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        # get patch data\n",
    "        row = self.rows[idx]\n",
    "        col = self.cols[idx]\n",
    "        cidx = self.cidxs[idx]\n",
    "        label = self.tissue_classes[idx]\n",
    "        self.total_sampled[label] += 1\n",
    "        \n",
    "        # Are dimensions of patch okay\n",
    "        idx_u = row - self.patch_minus\n",
    "        idx_d = row + self.patch_plus\n",
    "        idx_l = col - self.patch_minus\n",
    "        idx_r = col + self.patch_plus\n",
    "        pad_u = max(-idx_u,0); idx_u = max(idx_u,0)\n",
    "        pad_d = max(idx_d-image_size,0); idx_d = min(idx_d,image_size)\n",
    "        pad_l = max(-idx_l,0); idx_l = max(idx_l,0)\n",
    "        pad_r = max(idx_r-image_size,0); idx_r = min(idx_r,image_size)\n",
    "        \n",
    "        # get patch\n",
    "        patch = torch.from_numpy(\n",
    "            self.hdf5_files[cidx]['spectra'][idx_u:idx_d,idx_l:idx_r,*self.channels],\n",
    "        ).permute(2,0,1)\n",
    "        patch *= torch.from_numpy(\n",
    "            self.hdf5_files[cidx]['mask'][idx_u:idx_d,idx_l:idx_r,],\n",
    "        ).unsqueeze(0)\n",
    "        \n",
    "        # pad patch\n",
    "        patch = torch.nn.functional.pad(patch,(pad_l,pad_r,pad_u,pad_d,0,0))\n",
    "        \n",
    "        if self.augment:\n",
    "            patch = self.transforms(patch)\n",
    "        return patch,label\n",
    "\n",
    "    # split annotations from H x W x 3 to C x H x W, one/zerohot along C dimension\n",
    "    def split_annotations(self,annotations_img):\n",
    "        split = torch.zeros((len(self.annotation_class_colors),*annotations_img.shape[:-1]))\n",
    "        for c,col in enumerate(annotation_class_colors):\n",
    "            split[c,:,:] = torch.from_numpy(np.all(annotations_img == self.annotation_class_colors[c],axis=-1)) \n",
    "        return split\n",
    "    \n",
    "    # open every file \n",
    "    def open(self):\n",
    "        self.hdf5_files = []\n",
    "        self.tissue_classes = []\n",
    "        self.rows = []\n",
    "        self.cols = []\n",
    "        self.cidxs = []\n",
    "        \n",
    "        # for every core in dataset,\n",
    "        for cidx in range(0,len(self.hdf5_filepaths)):\n",
    "            # open annotations and remove edges and non-tissue px\n",
    "            annotation = self.split_annotations(cv2.imread(self.annotation_filepaths[cidx])[:,:,::-1])\n",
    "            mask = torch.from_numpy(cv2.imread(self.mask_filepaths[cidx])[:,:,1]) / 255\n",
    "            annotation *= mask\n",
    "            # for every class,\n",
    "            for cls in range(len(annotation_class_names)):\n",
    "                # get location of annotations, append to lists\n",
    "                r,c = torch.where(annotation[cls])\n",
    "                num_cls = annotation[cls].sum().int().item()\n",
    "                self.tissue_classes.extend([cls,]*num_cls)\n",
    "                self.cidxs.extend([cidx,]*num_cls)\n",
    "                self.rows.extend(r)\n",
    "                self.cols.extend(c)\n",
    "            # add open hdf5 file to list\n",
    "            self.hdf5_files.append(h5py.File(self.hdf5_filepaths[cidx],'r'))\n",
    "                \n",
    "        # construct data tensors\n",
    "        self.rows = torch.Tensor(self.rows).int()\n",
    "        self.cols = torch.Tensor(self.cols).int()\n",
    "        self.tissue_classes = torch.Tensor(self.tissue_classes).long()\n",
    "        self.cidxs = torch.Tensor(self.cidxs).int()\n",
    "        self.total_pixels = len(self.cidxs)\n",
    "\n",
    "    # close every open hdf5 file\n",
    "    def close(self):\n",
    "        for cidx in range(len(self.hdf5_files)):\n",
    "            self.hdf5_files[cidx].close()\n",
    "        self.hdf5_files = []\n",
    "        self.tissue_classes = []\n",
    "        self.xs = []\n",
    "        self.ys = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T17:22:18.659935700Z",
     "start_time": "2025-03-14T17:22:18.653518700Z"
    }
   },
   "id": "a8a3aa59fbf57012",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loader sizes:\n",
      "\ttrain: 5460\n",
      "\tval: 2221\n",
      "\ttest: 2117\n"
     ]
    }
   ],
   "source": [
    "dataset_train = ftir_patching_dataset(\n",
    "    hdf5_filepaths[where_train], mask_filepaths[where_train], annotation_filepaths[where_train], channels_used,\n",
    "    patch_dim = patch_dim, augment=use_augmentation,\n",
    ")\n",
    "dataset_val = ftir_patching_dataset(\n",
    "    hdf5_filepaths[where_val], mask_filepaths[where_val], annotation_filepaths[where_val], channels_used,\n",
    "    patch_dim = patch_dim, augment=False,\n",
    ")\n",
    "dataset_test = ftir_patching_dataset(\n",
    "    hdf5_filepaths[where_test], mask_filepaths[where_test], annotation_filepaths[where_test], channels_used,\n",
    "    patch_dim = patch_dim, augment=False,\n",
    ")\n",
    "\n",
    "# Instiantiate data loaders\n",
    "_, class_counts = np.unique(dataset_train.tissue_classes, return_counts=True)\n",
    "class_weights = 1 / class_counts\n",
    "class_weights = class_weights[dataset_train.tissue_classes]\n",
    "train_sampler = torch.utils.data.WeightedRandomSampler(class_weights, len(class_weights), replacement=True)\n",
    "\n",
    "_, class_counts = np.unique(dataset_val.tissue_classes, return_counts=True)\n",
    "class_weights = 1 / class_counts\n",
    "class_weights = class_weights[dataset_val.tissue_classes]\n",
    "val_sampler = torch.utils.data.WeightedRandomSampler(class_weights, len(class_weights), replacement=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, sampler=train_sampler,drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size, sampler=val_sampler,drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size,shuffle=False,drop_last=True)\n",
    "print(f\"loader sizes:\\n\\ttrain: {len(train_loader)}\\n\\tval: {len(val_loader)}\\n\\ttest: {len(test_loader)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T17:22:25.444564Z",
     "start_time": "2025-03-14T17:22:18.658904Z"
    }
   },
   "id": "c6bebd9eeed34711",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample some data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abdcc80122d23428"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/15\r"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "for iter in range(0, (samples_to_train // batch_size) + 1):\n",
    "    for bidx, (data, label) in enumerate(train_loader):\n",
    "        print(f\"{bidx}/{(samples_to_train // batch_size)}\",end=\"\\r\")\n",
    "        train_data.append(data.squeeze().cpu().numpy())\n",
    "        train_labels.append(label.squeeze().cpu().numpy())\n",
    "        \n",
    "        if iter*len(train_loader) + bidx*batch_size > samples_to_train:\n",
    "            end = True\n",
    "            break\n",
    "    if end:\n",
    "        break\n",
    "train_data = np.concatenate(train_data,axis=0)\n",
    "train_labels = np.concatenate(train_labels,axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T17:22:57.358503200Z",
     "start_time": "2025-03-14T17:22:25.445616500Z"
    }
   },
   "id": "e49ecda26ba39e97",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define, train Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f550708e9f4c74c5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\w37262do\\AppData\\Local\\anaconda3\\envs\\phd-env\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm accuracy on the train data: 0.8363970588235294\n",
      "rf accuracy on the train data: 0.9448529411764706\n"
     ]
    }
   ],
   "source": [
    "if r_method == 'pca':\n",
    "    svm_model = svm_model = Pipeline([\n",
    "        (\"pca\",PCA(n_components=reduce_dim)),\n",
    "        (\"normalise\",StandardScaler(),),\n",
    "        (\"kernel_map\",Nystroem(kernel='rbf',gamma=1e-4,n_components=500),),\n",
    "        (\"svm\",LinearSVC(C=1.0,)),\n",
    "    ])\n",
    "    rf_model = Pipeline([\n",
    "        (\"pca\",PCA(n_components=reduce_dim)),\n",
    "        (\"normalise\",StandardScaler(),),\n",
    "        (\"randomforest\",RandomForestClassifier(n_estimators=500, min_samples_leaf=10))\n",
    "    ])\n",
    "elif r_method == 'fixed':\n",
    "    svm_model = Pipeline([\n",
    "        (\"normalise\",StandardScaler(),),\n",
    "        (\"kernel_map\",Nystroem(kernel='rbf',gamma=1e-4,n_components=500),),\n",
    "        (\"svm\",LinearSVC(C=1.0,)),\n",
    "    ])\n",
    "    rf_model = Pipeline([\n",
    "        (\"normalise\",StandardScaler(),),\n",
    "        (\"randomforest\",RandomForestClassifier(n_estimators=500, min_samples_leaf=10))\n",
    "    ])\n",
    "\n",
    "svm_model.fit(train_data,train_labels)\n",
    "rf_model.fit(train_data,train_labels)\n",
    "print(f\"svm accuracy on the train data: {accuracy_score(svm_model.predict(train_data),train_labels)}\")\n",
    "print(f\"rf accuracy on the train data: {accuracy_score(rf_model.predict(train_data),train_labels)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T17:23:02.961884600Z",
     "start_time": "2025-03-14T17:22:57.359554900Z"
    }
   },
   "id": "33535f38f1458959",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "307cf693fb06cb7e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/2117\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_preds_svm,test_preds_rf, test_targets = [], [], []\n",
    "\n",
    "for bidx, (data, label) in enumerate(test_loader):\n",
    "    print(f\"{bidx}/{(len(test_loader))}\",end=\"\\r\")\n",
    "    data = data.squeeze().cpu().numpy()\n",
    "    label = label.squeeze().cpu().numpy()\n",
    "    pred_svm = svm_model.predict(data)\n",
    "    pred_rf = rf_model.predict(data)\n",
    "    \n",
    "    test_preds_svm.extend(pred_svm)\n",
    "    test_preds_rf.extend(pred_rf)\n",
    "    test_targets.extend(label)\n",
    "\n",
    "test_targets = np.array(test_targets); test_preds_svm = np.array(test_preds_svm); test_preds_rf = np.array(test_preds_rf)\n",
    "test_acc_svm = accuracy_score(test_targets, test_preds_svm)\n",
    "test_f1m_svm = f1_score(test_targets, test_preds_svm, average='macro')\n",
    "test_f1_svm = f1_score(test_targets, test_preds_svm, average=None)\n",
    "test_acc_rf = accuracy_score(test_targets, test_preds_rf)\n",
    "test_f1m_rf = f1_score(test_targets, test_preds_rf, average='macro')\n",
    "test_f1_rf = f1_score(test_targets, test_preds_rf, average=None)\n",
    "print(\"Metrics on entire testing set:\")\n",
    "print(f\"TEST ---- | RANDOMFOREST | OA: {test_acc_rf:.4f} | f1: {test_f1m_rf:.4f}\")\n",
    "for cls_idx, f1 in enumerate(test_f1_rf):\n",
    "    print(f\"{annotation_class_names[cls_idx]}{(20 - len(annotation_class_names[cls_idx])) * ' '} : {f1:.4f}\")\n",
    "    \n",
    "print(f\"TEST ---- | SVM | OA: {test_acc_svm:.4f} | f1: {test_f1m_svm:.4f}\")\n",
    "for cls_idx, f1 in enumerate(test_f1_svm):\n",
    "    print(f\"{annotation_class_names[cls_idx]}{(20 - len(annotation_class_names[cls_idx])) * ' '} : {f1:.4f}\")\n",
    "    \n",
    "    \n",
    "print(\"Total samples loaded for each class during TESTING\")\n",
    "for cls_idx, samples_loaded in enumerate(dataset_test.total_sampled.numpy()):\n",
    "    print(f\"{annotation_class_names[cls_idx]}{(20-len(annotation_class_names[cls_idx])) * ' '}:    {int(samples_loaded)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T17:23:10.836424600Z",
     "start_time": "2025-03-14T17:23:02.960762200Z"
    }
   },
   "id": "242a34c1a6fe3be8",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finish experiment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cd7e4042615b52"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Read existing results file\n",
    "if not is_local:\n",
    "    if os.path.isfile('results_svm.txt'):\n",
    "        f = open('results_svm.txt','r')\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "    else: \n",
    "        lines = [x+', \\n' for x in['seed',*annotation_class_names,'overall_acc','macro_f1']]\n",
    "        \n",
    "    # Process files\n",
    "    lines[0] = lines[0].replace('\\n',str(seed) + ', \\n')\n",
    "    for cls in range(n_classes):\n",
    "        lines[cls+1] = lines[cls+1].replace('\\n',str(test_f1_svm[cls]) + ', \\n' )\n",
    "    lines[n_classes+1] = lines[n_classes+1].replace('\\n',str(test_acc_svm) + ', \\n')\n",
    "    lines[n_classes+2] = lines[n_classes+2].replace('\\n',str(test_f1m_svm) + ', \\n')\n",
    "    \n",
    "    f = open('results_svm.txt','w')\n",
    "    f.write(''.join(lines))\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-14T17:23:10.834367400Z"
    }
   },
   "id": "bcb3c45e041764e8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Read existing results file\n",
    "if not is_local:\n",
    "    if os.path.isfile('results_rf.txt'):\n",
    "        f = open('results_rf.txt','r')\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "    else: \n",
    "        lines = [x+', \\n' for x in['seed',*annotation_class_names,'overall_acc','macro_f1']]\n",
    "        \n",
    "    # Process files\n",
    "    lines[0] = lines[0].replace('\\n',str(seed) + ', \\n')\n",
    "    for cls in range(n_classes):\n",
    "        lines[cls+1] = lines[cls+1].replace('\\n',str(test_f1_rf[cls]) + ', \\n' )\n",
    "    lines[n_classes+1] = lines[n_classes+1].replace('\\n',str(test_acc_rf) + ', \\n')\n",
    "    lines[n_classes+2] = lines[n_classes+2].replace('\\n',str(test_f1m_rf) + ', \\n')\n",
    "    \n",
    "    f = open('results_rf.txt','w')\n",
    "    f.write(''.join(lines))\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T17:23:10.837449700Z",
     "start_time": "2025-03-14T17:23:10.837449700Z"
    }
   },
   "id": "757aecd47164f768",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## save models\n",
    "if not is_local:\n",
    "    import pickle\n",
    "    with open(f'svm_model_{seed}.pt','wb') as f:\n",
    "        pickle.dump(svm_model,f)\n",
    "    with open(f'rf_model_{seed}.pt','wb') as f:\n",
    "        pickle.dump(rf_model,f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-14T17:23:10.839495400Z"
    }
   },
   "id": "ea8cc2a41098a8f8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset_train.close()\n",
    "dataset_val.close()\n",
    "dataset_test.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-14T17:23:10.842620700Z",
     "start_time": "2025-03-14T17:23:10.841540Z"
    }
   },
   "id": "10eaa319e3f02f12",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
